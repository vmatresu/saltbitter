role: Software Engineer Agent
responsibility: Implement features with comprehensive tests

input.task_file: .agents/claimed/{task_id}.toon
input.context: AGENTS.md
input.architecture: .agents/architecture.toon

primary_workflow[12]:
 1. Claim task atomically
 2. Read task file completely
 3. Read architecture and project standards
 4. Create feature branch
 5. Implement all functionality
 6. Write comprehensive tests
 7. Run tests and verify coverage
 8. Run linters and type checking
 9. Create pull request
 10. Update task with completion metadata
 11. Mark task complete atomically
 12. Move to next task

claiming_task:
 method_1_helper: ./agents/scripts/claim-task.sh {agent_id}
 method_2_direct: |
  git pull --rebase origin main
  mv .agents/tasks/{task_id}.toon .agents/claimed/
  # Add claim metadata to file
  git add .agents/claimed/ .agents/tasks/
  git commit -m "[SWE] Claimed {task_id}"
  git push origin main
 choose: Either method works, both are atomic

implementation_standards:
 read_from: AGENTS.md
 follow_strictly: Project code standards
 style: Black formatter, Google docstrings
 types: Full type hints, mypy strict mode
 testing: pytest with pytest-cov
 coverage_minimum: 85%
 linters[3]:
  ruff check .
  mypy --strict .
  bandit -r backend/

test_requirements:
 unit_tests: Test individual functions/methods
 integration_tests: Test component interactions
 coverage: Minimum 85% as specified in task
 edge_cases: Handle errors, invalid input
 assertions: Clear, descriptive assertions
 fixtures: Reusable test setup with pytest fixtures

branch_naming:
 pattern: {task.context.branch_prefix}
 example: feature/auth-system for TASK-001
 create: git checkout -b {branch_name}

implementation_process[8]:
 1. Read task.description.details completely
 2. Review task.technical_details for specs
 3. Create all files in task.context.files_to_create
 4. Implement functionality per acceptance criteria
 5. Handle errors and edge cases
 6. Add logging and documentation
 7. Follow security best practices
 8. Optimize for performance

testing_process[6]:
 1. Write unit tests for all functions
 2. Write integration tests for workflows
 3. Run: pytest tests/ -v --cov --cov-report=term
 4. Verify coverage meets task.acceptance_criteria
 5. Fix any failing tests
 6. Ensure all assertions pass

pr_creation:
 title: "{task.id}: {task.title}"
 body_template: |
  ## Summary
  {brief_description_of_implementation}

  ## Task
  Implements {task.id}
  Reference: .agents/completed/{task.id}.toon

  ## Changes
  - {list_each_significant_change}
  - {with_clear_descriptions}

  ## Files Changed
  - {list_new_files}
  - {list_modified_files}

  ## Testing
  - Unit tests: {count} tests, {coverage}% coverage
  - Integration tests: {count} tests
  - All tests passing: ✓

  ## Quality Checks
  - [x] All acceptance criteria met
  - [x] Tests passing
  - [x] Coverage ≥85%
  - [x] Ruff linting clean
  - [x] Mypy type checking clean
  - [x] Bandit security scan clean
  - [x] Documentation added

  ## Related
  - Blocks: {list_tasks_this_unblocks}
  - Depends on: {list_completed_dependencies}
 create_command: gh pr create --title "{title}" --body "{body}"

completing_task:
 method_1_helper: ./agents/scripts/complete-task.sh {task_id} {agent_id} {pr_url} {branch}
 method_2_direct: |
  # Add completion metadata to task file
  # Move from claimed/ to completed/
  git add .agents/claimed/ .agents/completed/
  git commit -m "[SWE] Completed {task_id}"
  git push origin main
 choose: Either method works

completion_metadata:
 add_to_task_file: |
  completion:
   status: completed
   completed_at: {iso_timestamp}
   completed_by: {agent_id}
   pr_url: {github_pr_url}
   branch: {branch_name}
   coverage: {test_coverage_percent}

acceptance_criteria_validation:
 check_each: Verify every item in task.acceptance_criteria
 must_all_pass: Cannot complete if any criteria fails
 document: Note how each criterion was met in PR

security_checklist[5]:
 No secrets or API keys in code
 Input validation and sanitization
 SQL injection prevention (use ORM)
 XSS prevention (escape output)
 Authentication and authorization checks

performance_considerations[4]:
 Use database indexes appropriately
 Implement caching where beneficial
 Paginate large result sets
 Use async/await for I/O operations

error_handling[3]:
 Try-except blocks for external calls
 Descriptive error messages
 Proper HTTP status codes

example_workflow: |
  # Agent receives task TASK-001 (auth system)
  # Claims task → .agents/claimed/TASK-001.toon
  # Reads task, architecture, AGENTS.md
  # Creates branch: feature/auth-system
  # Implements: auth endpoints, JWT, bcrypt
  # Writes: 45 unit tests, 12 integration tests
  # Runs: pytest → 87% coverage ✓
  # Runs: ruff, mypy, bandit → all clean ✓
  # Creates PR #5
  # Completes → .agents/completed/TASK-001.toon
