# ADR-004: EU AI Act Compliance Strategy for AI Features

## Status
Accepted

## Context
The EU AI Act (enacted 2024, full enforcement by 2026) regulates AI systems based on risk level. Our AI features (practice companions, relationship coaching) qualify as "limited risk" systems requiring transparency obligations.

### Regulatory Requirements
**EU AI Act Article 52**: Users must be informed when interacting with AI systems
**California SB 243** (2024): Similar disclosure and opt-out requirements
**GDPR**: Data protection and consent requirements still apply

### Our AI Features
1. **AI Practice Companions**: GPT-4 powered conversation practice (5 personas)
2. **Relationship Coaching**: AI-generated communication insights and tips
3. **Content Moderation**: Automated flagging of toxic content (Perspective API)
4. **Match Algorithm**: Partially AI-assisted (interest embeddings)

### Compliance Options
- **Option A**: Remove AI features entirely (avoid regulation)
- **Option B**: Minimal compliance (disclosure only)
- **Option C**: Comprehensive compliance + ethical leadership

## Decision
We will implement **comprehensive compliance with ethical leadership** (Option C), exceeding regulatory minimums.

## Consequences

### Positive
- **Legal Protection**: Future-proof against regulatory changes
- **User Trust**: Transparency builds brand credibility
- **Competitive Advantage**: First-mover in ethical AI dating
- **User Safety**: Clear disclosure prevents deception
- **Ethical Brand**: Aligns with privacy-first mission
- **Premium Feature**: Transparency builds trust for paid coaching features

### Negative
- **Development Overhead**: 10-15% additional engineering effort
- **User Friction**: Disclosure modals may reduce AI feature adoption
- **Competitive Disadvantage**: Competitors may hide AI usage for better metrics
- **Maintenance Burden**: Quarterly compliance reports required

### Mitigation
- Build compliance infrastructure as reusable components
- Frame transparency as competitive advantage in marketing
- Streamline disclosure UX (one-time modal, not every interaction)
- Automate compliance reporting to reduce manual work

## Implementation Requirements

### 1. Clear AI Labeling (Article 52)
```tsx
// All AI profiles display ðŸ¤– badge
<AvatarBadge>
  <RobotIcon /> AI Companion
</AvatarBadge>

// All AI-generated content labeled
<CoachingTip>
  <AILabel>Generated by AI</AILabel>
  <p>{aiGeneratedContent}</p>
</CoachingTip>
```

### 2. Disclosure Before First Interaction
```tsx
<Modal>
  <h2>You're about to chat with an AI</h2>
  <p>This is a practice companion powered by AI (GPT-4).
     It's designed to help you practice conversation skills
     in a safe environment.</p>
  <Checkbox>
    I understand I'm chatting with an AI, not a real person
  </Checkbox>
  <Button onClick={handleConsent}>Continue</Button>
  <Link>Learn more about our AI features</Link>
</Modal>
```

### 3. Opt-Out Mechanism
```python
# User settings
class UserSettings(BaseModel):
    ai_features_enabled: bool = False  # Opt-in, not opt-out
    ai_coaching_enabled: bool = False
    ai_content_moderation: bool = True  # Safety feature, default on
```

### 4. Transparency Logging
```python
@dataclass
class AIInteraction:
    id: UUID
    user_id: UUID
    ai_type: Literal["companion", "coaching", "moderation"]
    disclosure_shown: bool
    consent_granted: bool
    interaction_count: int
    created_at: datetime
    metadata: dict

# Log every AI interaction
ai_logger.log_interaction(
    user_id=user.id,
    ai_type="companion",
    disclosure_shown=True,
    consent_granted=True
)
```

### 5. Audit Trail & Reporting
```python
class ComplianceReporter:
    async def generate_quarterly_report(self) -> ComplianceReport:
        """Generate EU AI Act compliance report."""
        return ComplianceReport(
            total_ai_interactions=await self.count_interactions(),
            users_shown_disclosure=await self.count_disclosures(),
            users_opted_out=await self.count_opt_outs(),
            disclosure_acceptance_rate=await self.acceptance_rate(),
            complaints=await self.get_complaints(),
            incidents=await self.get_incidents(),
        )
```

### 6. Human Alternatives
All AI features must have human alternatives:
- AI companions â†’ Practice with real users (opt-in practice mode)
- AI coaching â†’ Community forums, human coaches (paid)
- Match algorithm â†’ Manual search and filters

## Monitoring & Enforcement

### Metrics
- Disclosure shown rate: Target 100%
- Opt-out rate: Track and analyze reasons
- User complaints about AI interactions
- False positives in content moderation

### Alerts
- If disclosure not shown: Block AI feature access
- If opt-out rate >20%: Review UX and value proposition
- If complaints spike: Review AI behavior logs

## Related Decisions
- ADR-003: Attachment theory algorithm (AI-assisted matching)
- ADR-009: AI practice companions implementation
- ADR-010: AI transparency system

## References
- [EU AI Act Full Text](https://artificialintelligenceact.eu/)
- [California SB 243](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB243)
- [GDPR Guidelines on AI](https://edpb.europa.eu/)

## Date
2025-11-17

## Authors
- Architect Agent
- Legal Team
- Compliance Officer
